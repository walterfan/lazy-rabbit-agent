version: "3"
services:
  memgraph:
    image: memgraph/memgraph:2.19.0
    container_name: memgraph
    ports:
      - "7687:7687"
      - "7444:7444"
    networks:
      - llm_agent_network

  nginx:
    # default ports 80, 443 - expose mapping as needed to host
    image: nginx:1.13-alpine
    container_name: llm_nginx
    env_file:
      - ../backend/.env
    restart: unless-stopped

    ports:
      - "1980:80"    # http
      - "1981:443"   # https
    volumes:
      - ../frontend:/var/www/html/web
      - ${NGINX_CONF}:/etc/nginx/conf.d/default.conf
      - ${NGINX_SSL_CERTS}:/etc/ssl:ro
      - ${NGINX_LOGS}:/var/log/nginx
    networks:
      - llm_agent_network

  web:
    container_name: llm_agent
    build: ../backend
    image: llm_agent
    command: ["sh", "-c", "uvicorn main:app --reload --host 0.0.0.0"]
    ports:
      - "8000:8000"
    volumes:
      - ./.env:/app/.env
    environment:
      - TZ=Asia/Shanghai
    networks:
      - llm_agent_network

  celery_worker:
    container_name: celery_worker
    build: ../backend
    image: echo_llm_agent
    command: ["sh", "-c", "celery -A worker.celery_app worker -B -l info"]
    volumes:
      - ../backend:/app
    env_file:
      - ../backend/.env
    depends_on:
      - web
    networks:
      - llm_agent_network

  celery_flower:
    container_name: celery_flower
    build: ../backend
    image: echo_llm_agent
    command: ["sh", "-c", "celery -A worker.celery_app flower --port=5555"]
    volumes:
      - ../backend:/app
    env_file:
      - ../backend/.env
    ports:
      - 5555:5555
    depends_on:
      - web
    networks:
      - llm_agent_network

networks:
  llm_agent_network:
    driver: bridge
